---
layout: post
title: Day 20 of 100 days of large language models
subtitle: Want to go super deep into LLMs?
cover-img: /assets/img/forest_path.jpg
tags: [learning, personal, 100 days of large language models, natural language processing, machine learning, artificial intelligence]
---
ğŸ”Š "Want to go super deep into LLMs? Do an advanced project with Langchain"...

ğŸ¤” Said a post I saw a while back. Leaving aside what's meant by advanced, & suggesting folks are better off grasping fundamentals like chunking, embedding, & transformer architectures, I'd ask "Why Langchain?".

âœ¨ OK, so Langchain is the go-to for LLM orchestration, boasting 62K GitHub stars. Great for PoCs with quick assembly of components into chains. Insightful for understanding different design patterns tailored for LLM tasks. The zero-shot ReAct framework for self-reasoning to a goal in 20 lines of code, powerful stuff!

â—However, the more I use it, the more I find it very opinionated & difficult to wrangle into customized use cases. Also, the needless abstraction of simple model interfaces from likes of OpenAI. And about those abstractions. Being kept updated to really leverage state-of-the-art models?

ğŸª² Further, is it really production ready, with 2K open GitHub issues?

ğŸ“œ Given this, some people advocate "roll your own" LLM orchestration in pure Python, while others say that's just reinventing the wheel. Or controversial - use no-code first!

â“ Anyone found it's easier, faster, & more reliable to develop LLM use cases without Langchain rather than with it? Would you go to production scale with it? Would love to hear your thoughts ğŸ™
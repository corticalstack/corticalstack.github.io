---
layout: post
title: Day 3 of #100DaysOfLargeLanguageModels
subtitle: Some LLM key terms
cover-img: /assets/img/forest_path.jpg
tags: [learning, personal, 100 days of large language models, natural language processing, machine learning, artificial intelligence]
---
üìñ Some key terms around LLMs from papers & other resources discovered on my LLM journey, re-written as one-liners.

‚≠ê Large Language Model (LLM) is a deep learning model like ChatGPT, based on transformer architecture, trained on huge amounts of text

‚≠ê Explicit prompts are clear instructions including the role, task, & output format, to guide an LLM's behaviour

‚≠ê Implicit prompts guide an LLM's behaviour without explicit instructions, relying on model general understanding, for more creativity

‚≠ê Prompt engineering crafts prompts to guide the LLM for best possible output

‚≠ê Completion is an LLM's output in response to a prompt

‚≠ê Generative AI is an AI instructed by a prompt input to create original content from existing data.

‚≠ê Hallucination is when an LLM generates outputs that sound plausible but incorrect

‚≠ê Chain-of-thought prompting aims to solve complex problems by decomposing prompts into intermediate step prompts

‚≠ê One-shot learning for a model trained to understand new concepts with only a single example

‚≠ê Few-shot learning for a model trained to understand new concepts with only a few examples

‚≠ê Foundational model is a pre-trained model like GPT-3 serving as a starting point for downstream tasks like information retrieval

‚≠ê Plugins / agents enable LLMs to access APIs for powerful capabilities like performing web searches for an up-to-date world view or fact-checking

‚≠ê Retrieval Augmented Generation (RAG) is the process of supplementing a prompt with additional information based on web searches or queries of internal documents

‚≠ê Vector database is a specialized type of dB designed to store & efficiently retrieve vector data based on similarity of, for e.g., an output from an LLM
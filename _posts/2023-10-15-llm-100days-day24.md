---
layout: post
title: Day 24 of 100 days of large language models
subtitle: Thoughts from Air Capital report on State of AI 2023
cover-img: /assets/img/forest_path.jpg
tags: [learning, personal, 100 days of large language models, natural language processing, machine learning, artificial intelligence]
---
Grab a â˜• & get comfy! Nathan Benaich released a whopper [163-page The State of AI 2023](https://www.stateof.ai/). Great review of a crazy year in AI. What resonated with me:

ðŸŒŸ GPT-4 the uncontested, most generally capable model. Solved tasks GPT-3.5 unable to, like the Uniform Bar Exam (90% score vs 10%). p.12

ðŸŒŸ Economic stakes high! OpenAI & Google technical reports on latest models don't disclose information useful for researchers. p.16

ðŸŒŸ LLaMa-2 70B by Meta competitive with ChatGPT on most tasks. Can use commercially, downloaded 32M times! p.19

ðŸŒŸ Although context windows (the text input length) of models growing in size, there's a "Lost in the Middle" performance problem. p.24

ðŸŒŸ Innovations including FlashAttention & 4-bit quantization tackle challenges like reducing memory footprint & accelerating inference. p.25

ðŸŒŸ Microsoft researchers find small language models (SLMs) trained with very specialized, curated datasets rival models 50x larger on specific tasks, e.g., phi-1.5. p.26

ðŸŒŸ Research to embed output from models with digital signatures to support identifying real from fake. p.30

ðŸŒŸ LLMs are great prompt engineers, out-performing human designed prompts. p.35

ðŸŒŸ Continuously monitor performance of GPT models, as they are continuously updated, with varying performance. p.36

ðŸŒŸ Google's Med_PaLM2 sets new SOTA results for medical-related benchmarks. p.63

ðŸŒŸ More than 70% of most cited AI papers in last 3 years have authors from US organizations. p.68

ðŸŒŸ NVIDIA joins $1T market cap club. p.70

ðŸŒŸ Not just top hyperscalers buying GPUs. Startup infra provider Lambda spending 9-figure $ sums, with over 45,000 GPUs installed. (p.71). Other companies buying vast quantities include Cohere, Inflection, & Imbue. (p.72)

ðŸŒŸ Compute is the new oil, even in Saudi Arabia! One university buys 3000 cards for LLM research. (p.73)

ðŸŒŸ Microsoft leads cloud service provider AI spending as % of total capex. p.79

ðŸŒŸ For mid-level professional writing, workers using ChatGPT took 40% less time, quality 18% better. p.91

ðŸŒŸ Compared to YouTube, Instagram, & TikTok, GenAI apps like ChatGPT suffer from lower retention rates & daily active users. p.94

ðŸŒŸ Legal complications on text and image copyright infringements surfacing. p.98

ðŸŒŸ Governments building GenAI compute capacity, but lagging behind private sector. p.131

ðŸŒŸ Ukraine a lab for AI-powered warfare. p.133

ðŸŒŸ Policymakers adopting wait-and-see to potential job losses. Support for Universal Basic Income. p.137

ðŸŒŸ Open vs Closed source debate continues; open source levels playing field but higher risk of misuse, versus closed source for greater security but less transparency. p.146

ðŸŒŸ Top predictions include craze on huge models seeing >$1B spent on training a single model, investigation of Microsoft/OpenAI deal on competition grounds, & a large AI company acquiring an AI chip company. p. 157